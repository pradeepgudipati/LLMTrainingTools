LLM_HOST='http://localhost'
LLM_PORT='1234'
LLM_MODEL_LLAMA3='QuantFactory/Meta-Llama-3-8B-Instruct-GGUF'
LLM_MODEL_LLAMA2='TheBloke/Llama-2-7B-Chat-GGUF'